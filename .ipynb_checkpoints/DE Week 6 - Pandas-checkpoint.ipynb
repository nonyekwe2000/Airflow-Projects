{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative;\">\n",
    "    <img src=\"logo.png\" style=\"position: absolute; top: -15px; left: -15px;\" width=\"110\" height=\"100\" />\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "## DE WEEK 6: PANDAS &#128060;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this session can be downloaded from [here](https://drive.google.com/file/d/1fG6gZ40u3NVd35Dwy5c4EmUe7ybfcJka/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pandas\n",
    "\n",
    "**Pandas** is a powerful open-source data manipulation and analysis library for Python. It provides easy-to-use data structures and functions for various data manipulation tasks, making it a fundamental tool for data engineers, data scientists, and analysts.\n",
    "\n",
    "Pandas introduces two main data structures: **Series** and **DataFrame**\n",
    "\n",
    "- **Pandas Series:** A one-dimensional array-like object containing a sequence of values and an associated array of data labels called an index. It can hold any data type.\n",
    "\n",
    "\n",
    "- **Pandas DataFrame:** A two-dimensional labeled data structure with columns of potentially different types. It is similar to a spreadsheet or SQL table.\n",
    "\n",
    "\n",
    "### Key Features and Advantages\n",
    "\n",
    "**Flexible Data Handling:** Pandas simplifies data manipulation tasks such as indexing, filtering, merging, and reshaping, allowing users to perform complex operations with minimal code.\n",
    "\n",
    "\n",
    "**Rich Functionality:** It offers a wide range of functions and methods for data cleaning, transformation, grouping, aggregation, and statistical analysis.\n",
    "\n",
    "\n",
    "**Time Series and Categorical Data Support:** Pandas provides specialized data structures and functions for working with time series data and categorical data, making it versatile for various analytical use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing and importing pandas\n",
    "# if not installed, install pandas using pip\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a Series from a list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Dataframes\n",
    "\n",
    "You can create a DataFrame from dictionaries, lists of dictionaries, or by reading data from external sources such as CSV files.\n",
    "\n",
    "Dataframes are created using the keyword ```pd.DataFrame()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data as Pandas DataFrame\n",
    "\n",
    "Reading data into a Pandas DataFrame is a fundamental operation in working with data in python. Pandas provides various functions to read data from different file formats such as CSV, Excel, SQL databases, JSON, and more. \n",
    "\n",
    "The general syntax is ```pd.read_fileformat()``` example \n",
    "\n",
    "- ```pd.read_csv()```\n",
    "- ```pd.read_sql()```\n",
    "- ```pd.read_excel()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Transforming data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() and tail() to view the first or 5 rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample(n) to view a random sample of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use info() and describe() to get basic info about your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# describe gives summary statistics on all numeric columns in the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. selecting data\n",
    "\n",
    "you can use ```df['column_name']``` to select a single column of the dataframe\n",
    "\n",
    "\n",
    "you can use ```df['column_name', 'column_name']``` to select a multiple columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select only one column from the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the unique categories. \n",
    "\n",
    "\n",
    "# How many orders were made from each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select two or more columns from the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting data row-wise\n",
    "\n",
    "\n",
    "you can use ```iloc[]``` and ```loc[]``` to select data by rows\n",
    "\n",
    "```df.iloc[]``` selects the rows based on integer (default) indexes\n",
    "\n",
    "```df.loc[]``` selects the rows based on custom indexes\n",
    "\n",
    "the syntax is ```df.iloc[row_slice, column_slice]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the 5th row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 1st to 5th row and the first 3 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filtering data\n",
    "\n",
    "You can filter rows based on a condition using the syntax ```df[condition]```\n",
    "\n",
    "You can have single conditons or multiple conditons joined using logical operators \n",
    "\n",
    "```df[condtion1 & condition2]``` \n",
    "\n",
    "```df[condition1 | condition2]``` *** the pipe means element-wise OR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for orders in Technology category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all unique sub categories in the dataframe\n",
    "\n",
    "## get the count of unique sub categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## filter for only Orders in technology category and Phones sub-category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Grouping and aggregations in Pandas\n",
    "\n",
    "The ```groupby()``` method in pandas is used to split the DataFrame into groups based on some criteria. It is often followed by an aggregation step to perform computations within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the mean sales for each category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean sales for each category and subcategory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can aggregate by multiple aggregate functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n",
    "\n",
    "Handling missing values is an important step in data processing/transformation. Pandas provides several methods for handling missing values, these includes:\n",
    "\n",
    "- dropping missing values ```dropna()```\n",
    "\n",
    "\n",
    "- simple imputation (filling missing values with a constant) ```fillna()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop missing values in the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill the missing values with the mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates\n",
    "\n",
    "You can use the ```drop_duplicates()``` to drop duplicate rows in a dataframe\n",
    "\n",
    "\n",
    "You can use the duplicated method ```df.duplicated()``` to check if there are duplicates in the dataframe first, before dropping the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for duplicates in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Adding or Droping Columns\n",
    "\n",
    "You can add new columns by creating the column and assigning values to the column. The values can be a constant or a calculation. \n",
    "\n",
    "```df['new_column'] = 7```\n",
    "\n",
    "```df['new_column'] =  expression```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can drop a single column or multiple columns from a DataFrame using the ```drop()``` method with the axis parameter set to 1.\n",
    "\n",
    "```df.drop('column', axis=1)```\n",
    "\n",
    "```df.drop(['column1', 'column2'], axis=1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "You can drop a single rows or multiple rows from a DataFrame using the ```drop()``` method with the axis parameter set to 0 (or ignored as this is the default value)\n",
    "\n",
    "```df.drop(row_index, axis=0)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** Use the ```inplace=True``` parameter to save the changes to the dataframe to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a single column with a constant value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a single column with a numerical calculation for Unit Price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a single column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop multiple columns from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop rows based on a condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Cleaning Column names\n",
    "\n",
    "You can perform cleaning operations on column names such as converting to lower case, removing white spaces, replacing white spaces with underscores, etc\n",
    "\n",
    "```df.columns``` is used to access a list of all columns in the dataframe. string methods can then be called on this list to clean them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the column names to lower case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace white spaces in the column names and replace then with underscores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Applying Transformations\n",
    "\n",
    "You can apply functions to a dataframe or specific rows or columns using the ```apply()``` function with axis parameter set to 1 for columns and 0 for rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## subtract 50 from all prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Renaming Columns\n",
    "\n",
    "You can rename columns using the ```rename()``` method and passing the column parameter a dictionary or list of dictionary mapping the old names to the new names.\n",
    "\n",
    "```df.rename(columns = {'old_name':'new_name'})```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename a column in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename multiple columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Converting datatypes in Pandas\n",
    "\n",
    "You can use the ```astype()``` method to convert columns into compatible datatypes\n",
    "\n",
    "\n",
    "**datetime** is a special pandas data type. You can convert a column to date using ```pd.to_datetime()``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the Sales column to string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the order date and ship date to a datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a column that holds the month of the order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Exporting Data to File using pandas\n",
    "\n",
    "Exporting data in pandas is straightforward and can be done using various file formats such as CSV, Excel, JSON, SQL, and more. \n",
    "\n",
    "You can use the ```df.to_csv(filename)``` method to export data to csv\n",
    "\n",
    "```df.to_xlsx()``` to export to excel format\n",
    "\n",
    "\n",
    "**Tip:** use ```index=False``` to exclude row index/indices when exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cleaned and transformed data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cleaned and transformed data to excel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Joining Data\n",
    "\n",
    "Joining and merging are methods used to combine data from different DataFrames based on one or more keys or indices. \n",
    "\n",
    "There are several types of joins available in pandas, including inner join, outer join, left join, and right join. \n",
    "\n",
    "You can join data using ```pd.merge(df1, df2, on='key_column', how='join_type')```\n",
    "\n",
    "\n",
    "You can also add rows of a dataframe to another dataframe (unions) using ```append```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform an inner join on 2 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform a left join on 2 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a union/append on 2 dataframes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
